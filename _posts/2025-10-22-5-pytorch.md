---
layout: single
title: "[PyTorch] 3. PyTorch Autograd: Automatic Differentiation for Deep Learning" 
date: 2025-10-22
categories: Pytorch
#header:
  #overlay_image: /assets/images/docker-container-tech.svg
  #overlay_filter: 0.5
  #teaser: /assets/images/docker-container-tech.svg
  #caption: "Create Docker Image"
Typora-root-url: ../
---

# PyTorch Autograd: Automatic Differentiation for Deep Learning

Automatic differentiation is at the heart of deep learning training. PyTorch's autograd system automatically computes gradients for tensor operations, making it easy to implement backpropagation. This tutorial will teach you how to use autograd effectively.

## Understanding requires_grad

The `requires_grad` parameter tells PyTorch to track operations on a tensor for gradient computation.

```python
import torch

x = torch.tensor([1.], requires_grad=True) # should be float (1.0)
print(x)
```

**Output:**
```
tensor([1.], requires_grad=True)
```

### Setting requires_grad after creation

```python
x = torch.tensor([1.])
print(x)
print(x.requires_grad)

x.requires_grad = True
print(x)
print(x.requires_grad)
```

**Output:**
```
tensor([1.])
False
tensor([1.], requires_grad=True)
True
```

## Computing gradients with backward()

When you perform operations on tensors with `requires_grad=True`, PyTorch builds a computational graph. The `backward()` method computes gradients.

### Basic gradient computation

```python
x = torch.tensor([1.], requires_grad=True)
y = x**2
print(y) # Can check PowBackward0

print(x.grad)
y.backward()
print(x.grad) # y=x**2 -> dy/dx = 2x = 2*1 = 2
```

**Output:**
```
tensor([1.], grad_fn=<PowBackward0>)
None
tensor([2.])
```

## Chain rule in action

PyTorch automatically applies the chain rule when computing gradients through multiple operations.

```python
x = torch.tensor([1.], requires_grad=True)
y = x**2
print(y) # Can check PowBackward0

z = 3*y  # 3 * x^2 -> dz/dx = 6x
print(z) # Can check MulBackward0

z.backward()
print(x.grad) # chain rule
```

**Output:**
```
tensor([1.], grad_fn=<PowBackward0>)
tensor([3.], grad_fn=<MulBackward0>)
tensor([6.])
```

### Complex computational graph

```python
x = torch.tensor([1.], requires_grad=True)
a = x**2
b = a+1
print(b) # Can check AddBackward0

c = b**2
c.backward()
print(x.grad)
```

**Output:**
```
tensor([2.], grad_fn=<AddBackward0>)
tensor([8.])
```

**Explanation:**
- $c = (x^2 + 1)^2$
- $\frac{dc}{dx} = 2(x^2 + 1) \cdot 2x = 4x(x^2 + 1)$
- At $x=1$: $4 \cdot 1 \cdot (1 + 1) = 8$

## Multiple variable gradients

You can compute gradients with respect to multiple variables simultaneously.

```python
x = torch.tensor([1.], requires_grad=True)
y = torch.tensor([1.], requires_grad=True)
z = 2*x**2 + y**2
print(z)
z.backward()
print(x.grad)
print(y.grad)
```

**Output:**
```
tensor([3.], grad_fn=<AddBackward0>)
tensor([4.])
tensor([2.])
```

**Explanation:**
- $z = 2x^2 + y^2$
- $\frac{\partial z}{\partial x} = 4x = 4 \cdot 1 = 4$
- $\frac{\partial z}{\partial y} = 2y = 2 \cdot 1 = 2$

### Product rule example

```python
x = torch.tensor([1.], requires_grad=True)
y = torch.tensor([1.], requires_grad=True)
z = y*x**2
z.backward()
print(x.grad)
print(y.grad)
```

**Output:**
```
tensor([2.])
tensor([1.])
```

**Explanation:**
- $z = y \cdot x^2$
- $\frac{\partial z}{\partial x} = 2xy = 2 \cdot 1 \cdot 1 = 2$
- $\frac{\partial z}{\partial y} = x^2 = 1^2 = 1$

## Vector gradients

When computing gradients for vector inputs, PyTorch requires `backward()` to be called on a scalar, so we often use `sum()`.

```python
x = torch.tensor([1., 2., 3.], requires_grad=True)
y = torch.sum(x**2) # 1^2 + 2^2 + 3^2 = 14
y.backward()

print(y)
print(x.grad) # 2x -> [2*1, 2*2, 2*3]
```

**Output:**
```
tensor(14., grad_fn=<SumBackward0>)
tensor([2., 4., 6.])
```

## Disabling gradient tracking

In some cases, you don't need gradients (e.g., during inference or for certain operations). PyTorch provides several ways to disable gradient tracking.

### Setting requires_grad to False

```python
x = torch.tensor([1.], requires_grad=True)
x.requires_grad = False
# Useful for transfer learning
y = x**2
print(y)
# y.backward() # error
```

**Output:**
```
tensor([1.])
```

### Using detach()

The `detach()` method creates a new tensor that doesn't require gradients, while keeping the original tensor unchanged.

```python
x = torch.tensor([2.], requires_grad=True)
x2 = x.detach() # detach creates new tensor which is requires_grad=False
print(x)
print(x2)

y = x**2
print(y)
y2 = x2**2
print(y2)
```

**Output:**
```
tensor([2.], requires_grad=True)
tensor([2.])
tensor([4.], grad_fn=<PowBackward0>)
tensor([4.])
```

### Practical use of detach

```python
# Usage of detach
x = torch.tensor([1.], requires_grad=True)
y = x**2
z = y.detach() # convert into variable
w = y+z        # w = x**2 + constant

w.backward()
print(x.grad)
```

**Output:**
```
tensor([2.])
```

**Explanation:** Since `z` is detached, it's treated as a constant. Therefore, $\frac{dw}{dx} = \frac{d(x^2)}{dx} = 2x = 2$.

### Using torch.no_grad()

The `torch.no_grad()` context manager disables gradient tracking for all operations within its scope. This is commonly used during model evaluation.

```python
# torch.no_grad
x = torch.tensor([1.], requires_grad=True)

# For model testing, unnecessary to update grad_fn
with torch.no_grad():
    y = x**2
    print(x.requires_grad)
    print(y)

print(x.requires_grad)
# y.backward() # error
y = x**2
print(y)

x = torch.tensor([1.], requires_grad=True)
x.requires_grad = False
y = x**2
print(x.requires_grad)
print(y)
# y.backward() # error
```

**Output:**
```
True
tensor([1.])
True
tensor([1.], grad_fn=<PowBackward0>)
False
tensor([1.])
```

## Visualizing computational graphs

You can visualize computational graphs using the `torchviz` library.

```python
from torchviz import make_dot

x = torch.tensor([1.], requires_grad=True)
# make_dot(x**2)

y = 2*x
z = 3+x
r = y+z
make_dot(r)
```

This creates a visual representation of the computational graph showing how operations are connected.

## Key takeaways

- **`requires_grad=True`**: Enables gradient tracking for a tensor
- **`backward()`**: Computes gradients using backpropagation
- **Chain rule**: PyTorch automatically applies the chain rule through computational graphs
- **Multiple variables**: Gradients can be computed for multiple input variables simultaneously
- **Disabling gradients**:
  - `requires_grad=False`: Prevents gradient tracking
  - `detach()`: Creates a new tensor without gradient tracking
  - `torch.no_grad()`: Context manager for temporarily disabling gradients
- **Computational graphs**: PyTorch builds dynamic computational graphs that can be visualized

Understanding autograd is essential for implementing custom loss functions, optimization algorithms, and advanced neural network architectures.

## Common use cases

1. **Training neural networks**: Automatic gradient computation for weight updates
2. **Transfer learning**: Freeze certain layers by setting `requires_grad=False`
3. **Model evaluation**: Use `torch.no_grad()` to speed up inference
4. **Custom loss functions**: Leverage autograd for automatic differentiation
5. **Gradient-based optimization**: Implement custom optimization algorithms

Autograd makes PyTorch a powerful framework for both research and production deep learning applications.
